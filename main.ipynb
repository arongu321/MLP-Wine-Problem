{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x3S9_EGUZXBG"
      },
      "outputs": [],
      "source": [
        "# --- Python Module Imports ---\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import sklearn as sk\n",
        "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler, FunctionTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold, cross_val_score\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.optimizers import Adam\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Description: Extracts the string as a column name after the closing parenthesis\n",
        "and before the opening parenthesis if 1 exists\n",
        "\n",
        "Arguments:\n",
        "  currentLine(string): Line to extract string\n",
        "\n",
        "Returns:\n",
        "  newLine(string): Name of column extracted from line of text\n",
        "\"\"\"\n",
        "def extractColumnName(currentLine):\n",
        "  openingParenIndex = currentLine.find(\")\") + 1\n",
        "  if \"(\" in currentLine:\n",
        "    closingParenIndex = currentLine.find(\"(\")\n",
        "    newLine = currentLine[openingParenIndex:closingParenIndex].strip()\n",
        "  else:\n",
        "    newLine = currentLine[openingParenIndex:].strip()\n",
        "  return newLine"
      ],
      "metadata": {
        "id": "GicYnDgCOGIJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Variable Initialization\n",
        "columnNames = [\"Class\"]\n",
        "pattern = r\"^\\d+\\)\"\n",
        "reachedLine = False"
      ],
      "metadata": {
        "id": "_2UKjUJnOcr9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate column names for dataset\n",
        "with open('wine.names', 'r') as columnsFile:\n",
        "  for line in columnsFile:\n",
        "    matchedPattern = False\n",
        "    if \"riclea@anchem.unige.it )\" in line:\n",
        "      reachedLine = True\n",
        "      continue\n",
        "    if reachedLine:\n",
        "      if len(line) > 3:\n",
        "        newLine = line.strip()\n",
        "        if re.match(pattern, newLine):\n",
        "          newLine = extractColumnName(newLine)\n",
        "          columnNames.append(newLine)"
      ],
      "metadata": {
        "id": "fdivt5Y4OZrF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Process data from Breast Cancer dataset file\n",
        "dataSet = pd.read_csv('wine.data', delimiter=',', names=columnNames)\n",
        "pd.set_option('display.max_rows', None)"
      ],
      "metadata": {
        "id": "XMla2dDROuUA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Pipelined Preprocessing of Dataset ###\n",
        "\n",
        "# Mean Imputation Function Filling out Missing Value with Mean Values of their Class\n",
        "def imputer(dataSet):\n",
        "  return dataSet.fillna(dataSet.groupby('Class').transform('mean'))\n",
        "\n",
        "# Do Min Max Scaling for All Columns Except for the Class Column\n",
        "def minMaxScaling(dataSet):\n",
        "  scaler = MinMaxScaler()\n",
        "  dataSetClass = dataSet['Class']\n",
        "  dataSetColumns = dataSet.drop(columns=['Class'])\n",
        "  scaledDataColumns = scaler.fit_transform(dataSetColumns)\n",
        "  scaledDataSet = pd.DataFrame(scaledDataColumns, columns=dataSetColumns.columns)\n",
        "  scaledDataSet.insert(0, 'Class', dataSetClass)\n",
        "  scaledDataSet['Class'].astype(int)\n",
        "  return scaledDataSet\n",
        "\n",
        "# Pipeline that preprocesses the dataset\n",
        "pipeline = Pipeline([\n",
        "    ('mean_impute', FunctionTransformer(imputer)),\n",
        "    ('min_max_scaler', FunctionTransformer(minMaxScaling))\n",
        "])\n",
        "\n",
        "dataSet = pd.DataFrame(pipeline.fit_transform(dataSet), columns=columnNames)"
      ],
      "metadata": {
        "id": "64Bankyy3uTR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting features and target(in this case Diagnosis) of dataset\n",
        "features = dataSet.drop(columns='Class', axis=1)\n",
        "targetVar = dataSet['Class']\n",
        "\n",
        "# Splitting dataset into training and testing data\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, targetVar, random_state=42, test_size=0.1, stratify=targetVar)"
      ],
      "metadata": {
        "id": "8eLtSm5MZ25U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Creating the multi-layer perceptron(MLP) network using backpropagation with\n",
        "momentum learning algorithm solving the Wine Dataset classification problem\n",
        "'''\n",
        "\n",
        "# MLP Model Function\n",
        "def createMLP(numLayers, numNeuronsPerLayer, learnRate):\n",
        "  mlpModel = Sequential()\n",
        "  for i in range(numLayers):\n",
        "    mlpModel.add(Dense(numNeuronsPerLayer, activation='relu'))\n",
        "  mlpModel.add(Dense(3, activation='softmax'))\n",
        "  mlpModel.compile(optimizer=Adam(learning_rate=learnRate), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "  return mlpModel\n",
        "\n",
        "# Hyperparameters of MLP(number of layers, neurons per layer, learning rate)\n",
        "paramGrid = {\n",
        "  'layers': [1, 2, 3],\n",
        "  'neurons_per_layer': [32, 64, 128],\n",
        "  'learning_rate': [0.001, 0.01, 0.1]\n",
        "}\n",
        "# Stratified K Fold\n",
        "stratKFold = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "# One Hot Encoder on Targeted Variable for Training Data\n",
        "encoder = OneHotEncoder(sparse_output=False)\n",
        "\n",
        "# MLP Hyperparameter Variables\n",
        "mean_f1Scores = {}\n",
        "test = 0\n",
        "highestF1Score = 0\n",
        "best_params = ()\n",
        "\n",
        "# Test MLP for each unique set of hyperparameters\n",
        "for layers in paramGrid['layers']:\n",
        "  for neuronsPerLayer in paramGrid['neurons_per_layer']:\n",
        "    for learnRate in paramGrid['learning_rate']:\n",
        "      # Retrieve F1 scores for each fold of the current MLP\n",
        "      f1Scores = []\n",
        "\n",
        "      # Store parameters of MLP in case the MLP achieves the highest F1 score\n",
        "      parameters = (layers, neuronsPerLayer, learnRate)\n",
        "\n",
        "      # There are 27 different MLPs for 27 sets of hyperparameters\n",
        "      mlpModel = createMLP(layers, neuronsPerLayer, learnRate)\n",
        "\n",
        "\n",
        "      for trainIdxes, validateIdxes in stratKFold.split(X_train, y_train):\n",
        "\n",
        "        # Get features data for training fold from training dataset\n",
        "        X_train_fold = X_train.iloc[trainIdxes]\n",
        "\n",
        "        # Get features data for validation fold from training dataset\n",
        "        X_validate_fold = X_train.iloc[validateIdxes]\n",
        "\n",
        "        # Get target data for training fold from training dataset\n",
        "        y_train_fold = pd.DataFrame(y_train.iloc[trainIdxes], columns=['Class'])\n",
        "\n",
        "        # Get target data for training fold from training dataset\n",
        "        y_validate_fold = pd.DataFrame(y_train.iloc[validateIdxes], columns=['Class'])\n",
        "\n",
        "        # One Hot Encoding with the Training and Validation Data of the Target Variable\n",
        "        y_train_encoded = encoder.fit_transform(y_train_fold[['Class']])\n",
        "        y_validate_encoded = encoder.fit_transform(y_validate_fold[['Class']])\n",
        "\n",
        "        # Fit the training data into the MLP model(note: target data must be one hot encoded)\n",
        "        mlpModel.fit(X_train_fold, y_train_encoded)\n",
        "\n",
        "        # Give predictions on what the target values should be for the validation features\n",
        "        y_predict = mlpModel.predict(X_validate_fold)\n",
        "\n",
        "        # Get the corresponding F1 score for the MLP with the predicted and validated target data\n",
        "        f1Score = f1_score(np.argmax(y_validate_encoded, axis=1), np.argmax(y_predict, axis=1), average='micro')\n",
        "        f1Scores.append(f1Score)\n",
        "\n",
        "      # Get Mean F1 Score of the hyperparameter set\n",
        "      meanF1Score = np.mean(f1Scores)\n",
        "\n",
        "      # Update best parameters for MLP and its corresponding mean F1 score\n",
        "      if meanF1Score > highestF1Score:\n",
        "        highestF1Score = meanF1Score\n",
        "        best_params = parameters"
      ],
      "metadata": {
        "id": "m_BF8DdqLYph"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display MLP model with best parameters and its corresponding F1 Score\n",
        "print(\"The best parameters are \" + str(best_params[0]) +\n",
        "      \" hidden layers with \" + str(best_params[1]) +\n",
        "      \" neurons per layer at a learning rate of \" + str(best_params[2]))\n",
        "print(\"The highest Mean F1 score is \" + str(highestF1Score))"
      ],
      "metadata": {
        "id": "sCCVJCUzCw1o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Train Network with All Training Data using the Best Parameters and Validate with the Test Data ###\n",
        "\n",
        "# Train Network with All the Training Data\n",
        "bestMLPModel = createMLP(best_params[0], best_params[1], best_params[2])\n",
        "X_train_all = X_train\n",
        "y_train_all = pd.DataFrame(y_train, columns=['Class'])\n",
        "y_train_all_encoded = encoder.fit_transform(y_train_all[['Class']])\n",
        "y_test = pd.DataFrame(y_test, columns=['Class'])\n",
        "y_test_encoded = encoder.fit_transform(y_test[['Class']])\n",
        "bestMLPModel.fit(X_train_all, y_train_all_encoded)\n",
        "y_predict_test = bestMLPModel.predict(X_test)\n",
        "\n",
        "# Get F1 score of MLP model with the test data\n",
        "f1ScoreTest = f1_score(np.argmax(y_test_encoded, axis=1), np.argmax(y_predict_test, axis=1), average='micro')\n",
        "print(\"The Mean F1 score of the Best MLP Model on this testing dataset is \"\n",
        "  + str(f1ScoreTest))"
      ],
      "metadata": {
        "id": "desY-F-rMtwv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}